{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 8605872,
          "sourceType": "datasetVersion",
          "datasetId": 5136555
        },
        {
          "sourceId": 8633094,
          "sourceType": "datasetVersion",
          "datasetId": 5169420
        }
      ],
      "dockerImageVersionId": 30732,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "CNN_Fashion_MNIST",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/playbase/ETL_Hive_Assignments/blob/main/CNN_Fashion_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'image-samples:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F5136555%2F8605872%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240611%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240611T154208Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D839378d351782c946209f62134fdec135afce48ab1a7200359675f327d0bcac9386a2b5e739e8f533597b870f9d3b65e05b0f8e0d06d16472f994829110e76402f8c2923f2299ac35ef330f572ed16b514a02eafc5461a1435fa2b2fb19613d175bd79a21f535eb4195a9496e2c1889616952b2bc5d742ff2d59ed3da0ce9674a4b195f873edb4e9d7e9d6b8303b7af9a2040d0c2b6c9428a9f9cf5991868527db28554498d0f7e61bd290e6e4a082a6666e91f7fcc0626a89e3e3403f82b9f36780475d9db49f81289b0f23ed0b723aa73f1bfe5145502a9ddae6dd128d2c3b1bf9f4402bf80132c77e7823d91f7ea365bfb51510909cc4ee8582461e688660,fashion-mnist:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F5169420%2F8633094%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240611%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240611T154208Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D9cd6e5caafc177f2b2d0457ac8a44370c6673973c7c881e0c9f0ce4609dd12a1c2d7f46bb2cb76d1302f3a2204ead9dbdf38ce3650e6dfbdb17dc88789b68f2e0b7cafa3a51ac8bcc5da5f6972cacb969ac3ab21875d95faa6f42fd2b34133e3c0fc26cc6914e603451984a9abcf8a47564adc4c991987e06b87403de960d5cc2920d0722345917d9400dcb5550331e016285035f6aaaa509fabdece90da9f0c28a4c961c5094ecad88208cff78b75eb6af13b94033b262cb6a0f1d498881c2940a665117d1ee0c4d3f720b8089aff9f7a60ae95e002d801ce3d9991ffffc452bd57b48a3da6c700b60f6882c6f3a2062e944aa747a35bf5a26b1cf3742022f9'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "ZqBeiceu9sbb"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python\n",
        "!pip install tensorflow\n",
        "!pip install keras\n",
        "!pip install visualkeras"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-07T14:53:14.268142Z",
          "iopub.execute_input": "2024-06-07T14:53:14.268727Z",
          "iopub.status.idle": "2024-06-07T14:54:21.7222Z",
          "shell.execute_reply.started": "2024-06-07T14:53:14.268682Z",
          "shell.execute_reply": "2024-06-07T14:54:21.720536Z"
        },
        "trusted": true,
        "id": "jutKqP9s9sbd",
        "outputId": "cb64d437-c438-454b-e7c9-009956ba93f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.10/site-packages (4.10.0.82)\nRequirement already satisfied: numpy>=1.21.2 in /opt/conda/lib/python3.10/site-packages (from opencv-python) (1.26.4)\nRequirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.15.0)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (23.5.26)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.10.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (16.0.6)\nRequirement already satisfied: ml-dtypes~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.26.4)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (21.3)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (69.0.3)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.9.0)\nRequirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.14.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.35.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.60.0)\nRequirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.1)\nRequirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.0)\nRequirement already satisfied: keras<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.26.1)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.32.3)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow) (3.1.1)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\nRequirement already satisfied: keras in /opt/conda/lib/python3.10/site-packages (2.15.0)\nRequirement already satisfied: visualkeras in /opt/conda/lib/python3.10/site-packages (0.0.2)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from visualkeras) (9.5.0)\nRequirement already satisfied: numpy>=1.18.1 in /opt/conda/lib/python3.10/site-packages (from visualkeras) (1.26.4)\nRequirement already satisfied: aggdraw>=1.3.11 in /opt/conda/lib/python3.10/site-packages (from visualkeras) (1.3.18.post0)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#All imports here\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import io\n",
        "import visualkeras\n",
        "import os\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.python import keras\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Activation, MaxPool2D, Flatten, Dropout, BatchNormalization\n",
        "from keras.optimizers import RMSprop,Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import visualkeras\n",
        "from keras.utils import plot_model\n",
        "import math"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-07T14:54:21.725079Z",
          "iopub.execute_input": "2024-06-07T14:54:21.725562Z",
          "iopub.status.idle": "2024-06-07T14:54:21.737704Z",
          "shell.execute_reply.started": "2024-06-07T14:54:21.725525Z",
          "shell.execute_reply": "2024-06-07T14:54:21.736284Z"
        },
        "trusted": true,
        "id": "itVktu-O9sbd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Data Collection\n",
        "from keras.datasets import fashion_mnist"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-07T14:50:45.98255Z",
          "iopub.execute_input": "2024-06-07T14:50:45.983003Z",
          "iopub.status.idle": "2024-06-07T14:50:45.994555Z",
          "shell.execute_reply.started": "2024-06-07T14:50:45.982969Z",
          "shell.execute_reply": "2024-06-07T14:50:45.993025Z"
        },
        "trusted": true,
        "id": "za6fePFk9sbd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
      ],
      "metadata": {
        "trusted": true,
        "id": "5RBqfJs39sbd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert x_train.shape == (60000, 28, 28)\n",
        "assert x_test.shape == (10000, 28, 28)\n",
        "assert y_train.shape == (60000,)\n",
        "assert y_test.shape == (10000,)"
      ],
      "metadata": {
        "trusted": true,
        "id": "YY9K7vjY9sbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Image Visualisation\n",
        "plt.imshow(x_train[100],plt.get_cmap('binary'))"
      ],
      "metadata": {
        "trusted": true,
        "id": "HeRvORYU9sbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[20000]"
      ],
      "metadata": {
        "trusted": true,
        "id": "42IV5JcZ9sbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=1\n",
        "for i in range(25,50):\n",
        "    plt.subplot(5,5,x)\n",
        "    plt.imshow(x_train[i],plt.get_cmap('binary'))\n",
        "    x+=1"
      ],
      "metadata": {
        "trusted": true,
        "id": "2_vT8aGI9sbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Encoding\n",
        "from keras.utils import to_categorical\n",
        "y_train1=to_categorical(y_train)\n",
        "y_test1=to_categorical(y_test)"
      ],
      "metadata": {
        "trusted": true,
        "id": "9UAA6dxn9sbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Build Model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,BatchNormalization,Dropout,Convolution2D,MaxPooling2D,Flatten\n",
        "nn=Sequential()"
      ],
      "metadata": {
        "trusted": true,
        "id": "HXyiBenN9sbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#16 forms of the same image\n",
        "nn.add(Convolution2D(filters=16,kernel_size=(3,3),input_shape=(28,28,1)))\n",
        "nn.add(MaxPooling2D(pool_size=(2,2)))\n",
        "nn.add(BatchNormalization())\n",
        "nn.add(Dropout(0.1))\n",
        "\n",
        "nn.add(Convolution2D(filters=16,kernel_size=(3,3)))\n",
        "nn.add(MaxPooling2D(pool_size=(2,2)))\n",
        "nn.add(BatchNormalization())\n",
        "nn.add(Dropout(0.1))\n",
        "\n",
        "nn.add(Convolution2D(filters=16,kernel_size=(3,3)))\n",
        "nn.add(MaxPooling2D(pool_size=(2,2)))\n",
        "nn.add(BatchNormalization())\n",
        "nn.add(Dropout(0.1))\n",
        "\n",
        "nn.add(Flatten())\n",
        "\n",
        "nn.add(Dense(1000,activation='relu'))\n",
        "nn.add(Dense(1000,activation='relu'))\n",
        "nn.add(Dense(1000))\n",
        "\n",
        "nn.add(Dense(10,activation='softmax'))"
      ],
      "metadata": {
        "trusted": true,
        "id": "NUy16GAi9sbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Compile\n",
        "nn.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "metadata": {
        "trusted": true,
        "id": "BXeKCl0G9sbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Add Callbacks\n",
        "from keras.callbacks import EarlyStopping\n",
        "Early=EarlyStopping(monitor='val_loss',patience=5)"
      ],
      "metadata": {
        "trusted": true,
        "id": "Wixf78189sbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualkeras.layered_view(nn)"
      ],
      "metadata": {
        "trusted": true,
        "id": "lsuVhaNO9sbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model\n",
        "hist=nn.fit(x_train,y_train1,validation_split=0.2,callbacks=[Early],epochs=5)"
      ],
      "metadata": {
        "trusted": true,
        "id": "K09zamJK9sbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visulaise the result\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])"
      ],
      "metadata": {
        "trusted": true,
        "id": "Y9FMgUj49sbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Accuracy\n",
        "plt.plot(hist.history['accuracy'])\n",
        "plt.plot(hist.history['val_accuracy'])"
      ],
      "metadata": {
        "trusted": true,
        "id": "BXMlEbls9sbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation Of Training data\n",
        "from sklearn.metrics import accuracy_score,classification_report,multilabel_confusion_matrix\n",
        "import numpy as np"
      ],
      "metadata": {
        "trusted": true,
        "id": "K1rTzvpj9sbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_train=nn.predict(x_train)\n",
        "y_pred_train[0]"
      ],
      "metadata": {
        "trusted": true,
        "id": "VIX3mMrp9sbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_train1=np.argmax(y_pred_train,axis=-1)\n",
        "y_pred_train1"
      ],
      "metadata": {
        "trusted": true,
        "id": "koWu3WFr9sbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "trusted": true,
        "id": "DGYdfqiE9sbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training Accuracy\n",
        "acc=accuracy_score(y_pred_train1,y_train)\n",
        "clf=classification_report(y_pred_train1,y_train)\n",
        "cnf=multilabel_confusion_matrix(y_pred_train1,y_train)\n",
        "\n",
        "print('Accuracy:',acc)\n",
        "print('Confusion matrix:\\n',cnf)\n",
        "print('classification Report:\\n',clf)"
      ],
      "metadata": {
        "trusted": true,
        "id": "b1TiesjX9sbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ts_pred=nn.predict(x_test)\n",
        "ts_pred"
      ],
      "metadata": {
        "trusted": true,
        "id": "eR5VgICy9sbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_test=np.argmax(ts_pred,axis=-1)\n",
        "y_pred_test"
      ],
      "metadata": {
        "trusted": true,
        "id": "nEYa-0Zy9sbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "trusted": true,
        "id": "ixyopjtN9sbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing Accuracy\n",
        "acc1=accuracy_score(y_pred_test,y_test)\n",
        "clf1=classification_report(y_pred_test,y_test)\n",
        "cnf1=multilabel_confusion_matrix(y_pred_test,y_test)\n",
        "\n",
        "print('Accuracy:',acc1)\n",
        "print('Confusion matrix:\\n',cnf1)\n",
        "print('classification Report:\\n',clf1)"
      ],
      "metadata": {
        "trusted": true,
        "id": "3H_4a_OL9sbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = {0 : \"T-shirt/top\", 1: \"Trouser\", 2: \"Pullover\", 3: \"Dress\", 4: \"Coat\",\n",
        "          5: \"Sandal\", 6: \"Shirt\", 7: \"Sneaker\", 8: \"Bag\", 9: \"Ankle Boot\"}\n",
        "\n",
        "X_test__ = x_test.reshape(x_test.shape[0], 28, 28)\n",
        "fig, axis = plt.subplots(4, 4, figsize=(12, 14))\n",
        "for i, ax in enumerate(axis.flat):\n",
        "    ax.imshow(x_test[i], cmap='binary')\n",
        "    ax.set(title = f\"Real Class is {labels[y_test[i]]}\\nPredict Class is {labels[y_pred_test[i]]}\");\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "DkN7suRc9sbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fuZcFcKH9sbf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}